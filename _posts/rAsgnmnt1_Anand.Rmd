---
title: "YLPDS_Assignment1"
author: "Anand S"
date: "10 August 2015"
output: html_document
---

# YLP Data Science Course | Assignment-1

## Purpose

- We learned a few statistical fundas in the class which ran for over a week.
- An assignment is given to exercise the learned topics.
- Most of the topics learned so far belong only to **Exploratory Data Analysis**
- While the class was taught only in SAS, it's an opportunity for me to do the same in *R*.

> Time to test my skills!

## Dataset

- Dataset used for this assignment is `houseprices.csv`

## References

This section is updated as and when an external reference is used.

- [Exploratory Data Analysis with R](http://www.renzeconsulting.com/presentations/exploratory-data-analysis-with-r.pdf) and the code examples followed are [here](http://www.renzeconsulting.com/presentations.html)
- [Textbook] Data Mining and Business Analytics with R (available as pdf)
- [PPT pdf] Lectures-Quantiles
- Learn basic R for some basic Data Analysis - [Cyclismo Tutorials](http://www.cyclismo.org/tutorial/R/)
- Calculating **[MODE](https://www.youtube.com/watch?v=YvdYwC2YgeI&feature=youtu.be)** with *R*

## `houseprices.csv`

```{r}
housePrices <- read.csv('houseprices.csv') # load the data from csv file and save it as a dataframe
summary(housePrices) # show the summary statistics on this dataset
str(housePrices) # what is the structure and dimension of this dataset
head(housePrices) # show a few top rows
names(housePrices) # show the column names
sum(is.na(housePrices)) # Are there missing values?
housePrices = na.omit(housePrices) # Just in case! If there are missing values, omit them.
```
From here, determine the data types of each column. I should be able to replace the code below with a 'for' loop.
```{r}
class(housePrices$Price)
class(housePrices$Living.Area)
class(housePrices$Bathrooms)
class(housePrices$Bedrooms)
class(housePrices$Lot.Size)
class(housePrices$Age)
class(housePrices$Fireplace)
```

## Question-1

> Prepare a brief report summarizing the home values (prices) in this area.
Use both graphical and numerical summaries. Your report should briefly describe what those summaries tell you, and anything of particular note/interest.

### Some basic summary stats

```{r}
mean(housePrices$Price)
median(housePrices$Price)
mode(housePrices$Price)
max(housePrices$Price)
min(housePrices$Price)
var(housePrices$Price)
sd(housePrices$Price)
```

### Univariate statistics for qualitative variable

```{r}
summary(housePrices$Price)
summary(housePrices$Age)
```

### Univariate visualization for quantitative variable

```{r}
library(ggplot2)
plot(x = housePrices$Price, y = rep(0, nrow(housePrices)), ylab = "")
```

But this visualization doesn't really inform much except for a couple outliers. For much better visualization, let us use box plot.

```{r}
boxplot(housePrices$Price, ylab = "House Prices", horizantal = TRUE)
```

This gives some information. Notice that the outliers appear more clearly in this way.

A histogram of prices.

```{r}
hist(housePrices$Price)
points(housePrices$Price, housePrices$Price * 0)
```

Let us view the distribution.

```{r}
plot(density(housePrices$Price))
points(housePrices$Price, housePrices$Price * 0)
```

## Question-2

> Does the normal model provide a good description of the prices? Use a Normal Quantile plot to frame your response.

> According to the above density plot, it looks like the distribution is right-skewed. Also, **the mean 163862.1**, **the median 151917** and **the mode 139079** values are close to the same number but not exactly the same. Normal quantile plot follows in the following sections.

By the way, R does not provide a direct function to calculate the mode, although there is a function `mode()`. This `mode()` function just tells the type of the storage used to store a variable. But not the statistical mdoe. So, to calculate the mode in R, I used a reference and below is the process.

- Put all the observations in the variable column, 'Price', into a variable.
- Convert it into a table with the first row showing the original observations as column title and the number of times each observation repeats in the next row. So it is a table with two rows where the first row is the names() of the values in the second row. 
- With this, the first row consists of our original observation values from the given data converted as strings and the second row shows the frequency of each observation value.
- Using names() function, call that observation value which has the highest frequency.
- Use max() function to see the frequency of that observation.

```{r}
prices <- housePrices$Price 
temp <- table(as.vector(prices)) 
names(temp)[temp == max(temp)]
max(temp)
```

## Quantiles & Quantile Plots

### Quantile Plot
```{r}
quantile(housePrices$Price)
x = housePrices$Price
n = length(x)
plot((1:n - 1)/(n-1), sort(x), type = "l", main = "Quantiles for the House Prices Data", xlab = "Sample Fraction", ylab = "Sample Quantile")
```

### Quantile-Quantile Plot
```{r}
x = housePrices$Price
y = housePrices$Living.Area
m = max(length(x), length(y))
p = (1:m - 1)/(m-1) # sample fraction
qx = quantile(x, p)
qy = quantile(y, p)
plot(qx, qy)
qqnorm(x)
qqline(x) # This plot signifies "skewed to the right. (Ref: lecture-quantiles.pdf"
```

## Question-3 {TBD}

> Irrespective of your response to Q2, assume that Price ~ N(164K, (68K)<sub>2</sub>).

> Given this:
> A. Calculate the following probabilities – P(Price > 92.8K), P(Price <255.5K). Do these numbers agree with what you see in the data?
> B. Once again, assuming the above normal distribution, what percentage of houses should have a value less than 232K? Does that agree with the data?
> C. Based on the theoretical model, what do you expect should be the price of a house that is exactly on the 3rd quartile (75th percentile,).How does that compare to the actual?

## Question-4

> Create a histogram and box plot for the Living Area variable. What does the histogram tell you that the box plot does not, and vice-versa? Is the distribution symmetric? Check the skewness measure to see if it is consistent with your observation.

```{r}
hist(housePrices$Living.Area)
boxplot(housePrices$Living.Area)
density(housePrices$Living.Area)
plot(density(housePrices$Living.Area))
```

Definitely, the boxplot would not tell me much about the skewness although experienced analysts may be able to recognize it. But the histogram clearly shows the kind of distribution and it is right-skewed.

#### Measureing Skewness

```{r}
library(moments)
skewness(housePrices$Living.Area)
kurtosis(housePrices$Living.Area)
```


## Question-5

> Create a new column in the dataset by taking the logarithm of the Living Area variable. Is the normal distribution a better fit for this variable or the original (Living Area) variable? Why do you think this is the case?

```{r}
x = housePrices$Living.Area
hist(x)
points(x, x * 0)
plot(density(x))
points(x, x * 0)
# with logarithm
logx = log10(x)
hist(logx)
plot(density(logx))
```

> Comparing graphs plotted with Living.Area observations versus **log(Living.Area)** observations, it looks like the plot got better. Without logarithm, the plot looks more like a right-skewed distribution, while with logarithm, it appears close to normal.

## Question-6

> Create the 90%, 95%, and 99% confidence intervals for the average home price and explain what these mean. How do the margins of error for these three confidence intervals compare? Does that make sense? Before creating the confidence intervals, be sure to check the conditions necessary to create confidence intervals (and briefly describe this in your submission). Assume that the population standard deviation of the home prices is 64,000.

#### Conditions to use Confidence Intervals



If the standard deviation of the home prices is, s = 64000 and sample size n = 1047, the 95% confidence interval is calculated in *R* using the follwing formula.

`qnorm(0.975) * s / sqrt(n)`

Then:

```{r}
m <- mean(housePrices$Price)
s <- 64000
n <- nrow(housePrices)
error <- qnorm(0.975)*s / sqrt(n)
left <- m - error
right <- m + error
left
right
```

This signifies that the true mean, **m=163862.1** has 95% probability of being in the interval between **159985.5** and **167738.8**.

The easier way of finding confidence intervals at the requires 90%, 95%, and 99% is by using `t.test()` function, as follows.

```{r}
t.test(housePrices$Price)
t.test(housePrices$Price, conf.level = 0.9)
t.test(housePrices$Price, conf.level = 0.99)
```
Therefore, the confidence intervals on Price data are as follows:

- 90% interval: 160420.1 and 167304.2
- 95% interval: 159759.6 and 167964.7
- 99% interval: 158466.8 and 169257.4

#### Comparing margins of errors:

```{r}
ci90 <- 160420.1 : 167304.2
ci95 <- 159759.6 : 167964.7
ci99 <- 158466.8 : 169257.4
boxplot(ci90, ci95, ci99)
```

Therefore, the margin of error on a 90% confidence interval is smaller than the other two.

## Question-7

> Your friend has asked you to provide an estimate for the 95th percentile of home prices in this market. Which (if any) of the above confidence intervals can you use to give an answer? Describe briefly.

> Based on the above plot comaring confidence intervals, it seems better to use 90% confidence level since the error margin is the least in this case.

## Bivariate visualization for two quantitative variables: Price & Lot.size

### Prices Vs. Lot.sizes
```{r}
plot(housePrices$Price, housePrices$Lot.Size)
plot(housePrices$Price, housePrices$Lot.Size, col = housePrices$Age, pch=19)
legend("bottomright", as.character(levels(cut(housePrices$Age, 5))), col=1:5, pch=19, cex=1)
boxplot(log10(housePrices$Price), log10(housePrices$Living.Area), names = c("House Prices", "Living Area"), main = "Comparing Boxplots")
```

### Prices Vs. Living.areas
```{r}
plot(housePrices$Price, housePrices$Living.Area)
fit <- lm(housePrices$Living.Area ~ housePrices$Price)
abline(fit)
class(fit)
summary(fit)
```

### Pearson's R for Correlation Measure
```{r}
cor.test(housePrices$Price, housePrices$Living.Area)
```

The above statistics, particularly the `cor` number signifies that the correlation between house prices and the living area in each house has about 77% correlation and the plot above clearly shows the linearity.

## Question-8

> The sample data given to you all come from home sales within the past 12months. Suppose you had sample data of the same size each year going back several years, and calculated the average sale price for each year. What kind of distribution do you expect to see for these averages and why? (Include the parameters of the distribution in your response,assuming that the house prices don’t change i. e. go up or down, overtime. Clearly, this is not a great assumption but make it anyway.)

If we assume there is no change in house prices during those years, the distribution will look similar to that of the current data.

# A Graphical Overview of the Whole Dataset

```{r}
plot(housePrices)
```


